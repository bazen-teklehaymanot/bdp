{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6565e3f8",
   "metadata": {},
   "source": [
    "# Analyzing New York City Taxi Data with Spark Structured Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983cb494",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55974225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "import time\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.sql.functions import explode, lead, col, unix_timestamp, sum\n",
    "from pyspark.sql.functions import split\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType, TimestampType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aea8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.builder.appName(\"NYTaxiTrips\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb58cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTSTRAP_SERVERS = os.environ.get('BOOTSTRAP_SERVERS')\n",
    "assert BOOTSTRAP_SERVERS is not None, 'BOOTSTRAP_SERVERS must be set'\n",
    "\n",
    "TRIP_TOPIC = 'trips'\n",
    "FARE_TOPIC = 'fares'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35005b8",
   "metadata": {},
   "source": [
    "Be sure to start the stream on Kafka!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e622d5b-ef4d-4d78-abcb-e9edc2305ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_schema = StructType(\n",
    "    [\n",
    "        StructField(\"medallion\", StringType(), False),\n",
    "        StructField(\"hack_license\", StringType(), False),\n",
    "        StructField(\"vendor_id\", StringType(), False),\n",
    "        StructField(\"rate_code\", IntegerType(), False),\n",
    "        StructField(\"store_and_fwd_flag\", StringType(), False),\n",
    "        StructField(\"pickup_datetime\", TimestampType(), False),\n",
    "        StructField(\"dropoff_datetime\", TimestampType(), False),\n",
    "        StructField(\"passenger_count\", IntegerType(), False),\n",
    "        StructField(\"trip_time_in_secs\", IntegerType(), False),\n",
    "        StructField(\"trip_distance\", IntegerType(), False),\n",
    "        StructField(\"pickup_longitude\", IntegerType(), False),\n",
    "        StructField(\"pickup_latitude\", IntegerType(), False),\n",
    "        StructField(\"dropoff_longitude\", IntegerType(), False),\n",
    "        StructField(\"dropoff_latitude\", IntegerType(), False),\n",
    "        StructField(\"timestamp\", TimestampType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fare_schema = StructType(\n",
    "    [\n",
    "        StructField(\"medallion\", StringType(), False),\n",
    "        StructField(\"hack_license\", StringType(), False),\n",
    "        StructField(\"vendor_id\", StringType(), False),\n",
    "        StructField(\"pickup_datetime\", TimestampType(), False),\n",
    "        StructField(\"payment_type\", StringType(), False),\n",
    "        StructField(\"fare_amount\", DoubleType(), False),\n",
    "        StructField(\"surcharge\", DoubleType(), False),\n",
    "        StructField(\"mta_tax\", DoubleType(), False),\n",
    "        StructField(\"tip_amount\", DoubleType(), False),\n",
    "        StructField(\"tolls_amount\", DoubleType(), False),\n",
    "        StructField(\"total_amount\", DoubleType(), False),\n",
    "        StructField(\"timestamp\", TimestampType(), False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69712d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "lines = (spark.readStream                        # Get the DataStreamReader\n",
    "  .format(\"kafka\")                                 # Specify the source format as \"kafka\"\n",
    "  .option(\"kafka.bootstrap.servers\", BOOTSTRAP_SERVERS) # Configure the Kafka server name and port\n",
    "  .option(\"subscribe\", TRIP_TOPIC)                       # Subscribe to the \"en\" Kafka topic \n",
    "  .option(\"startingOffsets\", \"earliest\")           # The start point when a query is started\n",
    "  .option(\"maxOffsetsPerTrigger\", 100)             # Rate limit on max offsets per trigger interval\n",
    "  .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0908a108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
      "| key|               value|topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     0|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     1|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     2|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     3|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     4|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     5|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     6|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     7|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     8|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|     9|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    10|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    11|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    12|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    13|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    14|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    15|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    16|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    17|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    18|2024-06-04 17:20:...|            0|\n",
      "|NULL|[7B 22 6D 65 64 6...|trips|        0|    19|2024-06-04 17:20:...|            0|\n",
      "+----+--------------------+-----+---------+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = (lines.writeStream\n",
    "  .outputMode(\"append\")\n",
    "  .format(\"memory\")\n",
    "  .queryName(\"myQuery\")\n",
    "  .start())\n",
    "\n",
    "import time\n",
    "time.sleep(10)\n",
    "\n",
    "spark.sql(\"SELECT * FROM myQuery\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a46c68-44ab-4e3a-90fb-d334423e4acc",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24187ef-e5b4-4fa7-bab5-60aa94412a05",
   "metadata": {},
   "source": [
    "### QUERY-1\n",
    "\n",
    "Utilization over a window of 5, 10, and 15 minutes per taxi/driver. This can be computed by computing the idle time per taxi. How does it change? Is there an optimal window?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b2d7ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- rate_code: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_time_in_secs: integer (nullable = true)\n",
      " |-- trip_distance: integer (nullable = true)\n",
      " |-- pickup_longitude: integer (nullable = true)\n",
      " |-- pickup_latitude: integer (nullable = true)\n",
      " |-- dropoff_longitude: integer (nullable = true)\n",
      " |-- dropoff_latitude: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_cleaned_df = lines.select(from_json(col(\"value\").cast(\"string\"), trip_schema).alias(\"parsed_value\"))\n",
    "trips_cleaned_df = trips_cleaned_df.select(\"parsed_value.*\")\n",
    "trips_cleaned_df.printSchema()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d5b1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_if_exists(output_path,table_name):\n",
    "    data_exists = False\n",
    "    for _i in range(60): # you can replace this with while, currently timeouts after about 60 seconds\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            files = os.listdir(output_path)\n",
    "            for _f in files:\n",
    "                if \".parquet\" in _f:\n",
    "                    if len(os.listdir(f\"{output_path}/_delta_log\"))>0:\n",
    "                        print(\"data exists\")\n",
    "                        data_exists = True\n",
    "                        break\n",
    "            if data_exists:\n",
    "                spark.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} USING DELTA LOCATION '{table_name}'\") # table metastore is created once there is some data (.parquet) in the directory\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(e) # if you want to see the exceptions, uncomment this\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37880c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'output/trips'\n",
      "[Errno 2] No such file or directory: 'output/trips'\n",
      "[Errno 2] No such file or directory: 'output/trips'\n",
      "[Errno 2] No such file or directory: 'output/trips'\n",
      "[Errno 2] No such file or directory: 'output/trips'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "[Errno 2] No such file or directory: 'output/trips/_delta_log'\n",
      "data exists\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = 'trip_checkpoints'\n",
    "table_name = 'trips'\n",
    "output_dir = f\"output/{table_name}\"\n",
    "\n",
    "query = (trips_cleaned_df\n",
    "         .select(\"medallion\", \"pickup_datetime\", \"passenger_count\")\n",
    "         .groupBy(\"medallion\", F.window(\"pickup_datetime\", \"5 minutes\"))\n",
    "         .sum(\"passenger_count\")\n",
    "         .withColumnRenamed(\"sum(passenger_count)\", \"passenger_count\")\n",
    "            .writeStream\n",
    "            .outputMode(\"complete\")\n",
    "            .format(\"delta\")\n",
    "            .queryName(table_name)\n",
    "            .option(\"checkpointLocation\", checkpoint_dir)\n",
    "            .start(output_dir)\n",
    ")\n",
    "\n",
    "create_table_if_exists(output_dir,table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "729b244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+-------------------+\n",
      "|           medallion|        hack_license|vendor_id|rate_code|store_and_fwd_flag|    pickup_datetime|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|          timestamp|\n",
      "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+-------------------+\n",
      "|89D227B655E5C82AE...|BA96DE419E711691B...|      CMT|     NULL|                 N|2013-01-01 15:11:48|2013-01-01 15:18:10|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:35|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|     NULL|                 N|2013-01-06 00:18:35|2013-01-06 00:22:54|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:36|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|     NULL|                 N|2013-01-05 18:49:41|2013-01-05 18:54:23|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:36|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|     NULL|                 N|2013-01-07 23:54:15|2013-01-07 23:58:20|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:37|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|     NULL|                 N|2013-01-07 23:25:03|2013-01-07 23:34:24|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:37|\n",
      "|20D9ECB2CA0767CF7...|598CCE5B9C1918568...|      CMT|     NULL|                 N|2013-01-07 15:27:48|2013-01-07 15:38:37|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:38|\n",
      "|496644932DF393260...|513189AD756FF14FE...|      CMT|     NULL|                 N|2013-01-08 11:01:15|2013-01-08 11:08:14|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:38|\n",
      "|0B57B9633A2FECD3D...|CCD4367B417ED6634...|      CMT|     NULL|                 N|2013-01-07 12:39:18|2013-01-07 13:10:56|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:39|\n",
      "|2C0E91FF20A856C89...|1DA2F6543A62B8ED9...|      CMT|     NULL|                 N|2013-01-07 18:15:47|2013-01-07 18:20:47|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:39|\n",
      "|2D4B95E2FA7B2E851...|CD2F522EEE1FF5F5A...|      CMT|     NULL|                 N|2013-01-07 15:33:28|2013-01-07 15:49:26|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:40|\n",
      "|E12F6AF991172EAC3...|06918214E951FA000...|      CMT|     NULL|                 N|2013-01-08 13:11:52|2013-01-08 13:19:50|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:40|\n",
      "|E12F6AF991172EAC3...|06918214E951FA000...|      CMT|     NULL|                 N|2013-01-08 09:50:05|2013-01-08 10:02:54|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:41|\n",
      "|78FFD9CD0CDA541F3...|E949C583ECF62C8F0...|      CMT|     NULL|                 N|2013-01-10 12:07:08|2013-01-10 12:17:29|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:41|\n",
      "|237F49C3ECC11F502...|93C363DDF8ED9385D...|      CMT|     NULL|                 N|2013-01-07 07:35:47|2013-01-07 07:46:00|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:42|\n",
      "|3349F919AA8AE5DC9...|7CE849FEF67514F08...|      CMT|     NULL|                 N|2013-01-10 15:42:29|2013-01-10 16:04:02|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:42|\n",
      "|3349F919AA8AE5DC9...|7CE849FEF67514F08...|      CMT|     NULL|                 N|2013-01-10 14:27:28|2013-01-10 14:45:21|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:43|\n",
      "|4C005EEBAA7BF26B8...|351BE7D984BE17DB2...|      CMT|     NULL|                 N|2013-01-07 22:09:59|2013-01-07 22:19:50|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:43|\n",
      "|7D99C30FCE69B1A9D...|460C3F57DD9CB2265...|      CMT|     NULL|                 N|2013-01-07 17:18:16|2013-01-07 17:20:55|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:44|\n",
      "|E6FBF80668FE0611A...|36773E80775F26CD1...|      CMT|     NULL|                 N|2013-01-07 06:08:51|2013-01-07 06:13:14|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:44|\n",
      "|0C5296F3C8B16E702...|D2363240A9295EF57...|      CMT|     NULL|                 N|2013-01-07 22:25:46|2013-01-07 22:36:56|           NULL|             NULL|         NULL|            NULL|           NULL|             NULL|            NULL|2024-06-04 17:20:45|\n",
      "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = (trips_cleaned_df.writeStream\n",
    "  .outputMode(\"append\")\n",
    "  .format(\"memory\")\n",
    "  .queryName(\"ParsedTripData\")\n",
    "  .start())\n",
    "\n",
    "import time\n",
    "time.sleep(10)\n",
    "\n",
    "spark.sql(\"SELECT * FROM ParsedTripData\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37aeae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------+---------+-----------+\n",
      "|medallion|window|busy_time|idle_time|utilization|\n",
      "+---------+------+---------+---------+-----------+\n",
      "+---------+------+---------+---------+-----------+\n",
      "\n",
      "+---------+------+---------+---------+-----------+\n",
      "|medallion|window|busy_time|idle_time|utilization|\n",
      "+---------+------+---------+---------+-----------+\n",
      "+---------+------+---------+---------+-----------+\n",
      "\n",
      "+---------+------+---------+---------+-----------+\n",
      "|medallion|window|busy_time|idle_time|utilization|\n",
      "+---------+------+---------+---------+-----------+\n",
      "+---------+------+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import window, col, unix_timestamp, max, min\n",
    "\n",
    "window_durations = [5 * 60, 10 * 60, 15 * 60]\n",
    "\n",
    "for window_duration in window_durations:\n",
    "    window_col = window(\"pickup_datetime\", \"{} seconds\".format(window_duration))\n",
    "    df_windowed = df.groupBy(\"medallion\", window_col).agg((max(\"dropoff_datetime\").cast(\"long\") - min(\"pickup_datetime\").cast(\"long\")).alias(\"busy_time\"))\n",
    "    \n",
    "    df_windowed = df_windowed.withColumn(\"idle_time\", window_duration - col(\"busy_time\"))\n",
    "    \n",
    "    df_windowed = df_windowed.withColumn(\"utilization\", col(\"busy_time\") / window_duration)\n",
    "    \n",
    "    query = (df_windowed.writeStream\n",
    "      .outputMode(\"complete\")\n",
    "      .format(\"memory\")\n",
    "      .queryName(\"utilization_{}_minutes\".format(window_duration // 60))\n",
    "      .trigger(processingTime=\"5 second\")\n",
    "      .start())\n",
    "\n",
    "spark.sql(\"SELECT * FROM utilization_5_minutes\").show()\n",
    "spark.sql(\"SELECT * FROM utilization_10_minutes\").show()\n",
    "spark.sql(\"SELECT * FROM utilization_15_minutes\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746caef-fc7c-4d0e-98df-cdd6046393eb",
   "metadata": {},
   "source": [
    "### QUERY-2 \n",
    "\n",
    "The average time it takes for a taxi to find its next fare(trip) per destination borough. This can be computed by finding the time difference, e.g. in seconds, between the trip's drop off and the next trip's pick up within a given unit of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea404b-fc76-48f9-83d9-5946617863de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember you can register another stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268c285-d55c-4be3-8e5a-e7ddebb14153",
   "metadata": {},
   "source": [
    "### QUERY-3\n",
    "\n",
    "The number of trips that started and ended within the same borough in the last hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7ad21-59c2-4d4c-befe-9d1ceedbb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember you can register another stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0d685-c3ed-4b7d-8ebc-c3174ba55645",
   "metadata": {},
   "source": [
    "### QUERY-4 \n",
    "\n",
    "The number of trips that started in one borough and ended in another one in the last hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3578b-1960-4969-801b-adc2f45493a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
