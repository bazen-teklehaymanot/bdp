{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6565e3f8",
   "metadata": {},
   "source": [
    "# Analyzing New York City Taxi Data with Spark Structured Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983cb494",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "55974225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "import time\n",
    "import uuid\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import lag, col, avg, unix_timestamp, explode, lead, sum, split\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType, TimestampType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aea8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.builder.appName(\"NYTaxiTrips\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", spark._sc.defaultParallelism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb58cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOTSTRAP_SERVERS = os.environ.get('BOOTSTRAP_SERVERS')\n",
    "assert BOOTSTRAP_SERVERS is not None, 'BOOTSTRAP_SERVERS must be set'\n",
    "\n",
    "NYC_BOROUGHS_GEOJSON = \"nyc-boroughs.geojson\"\n",
    "assert os.path.exists(NYC_BOROUGHS_GEOJSON), f'{NYC_BOROUGHS_GEOJSON} not found'\n",
    "\n",
    "TRIP_TOPIC = 'trips'\n",
    "FARE_TOPIC = 'fares'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35005b8",
   "metadata": {},
   "source": [
    "Be sure to start the stream on Kafka!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e622d5b-ef4d-4d78-abcb-e9edc2305ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_trip_schema = StructType(\n",
    "    [\n",
    "        StructField(\"medallion\", StringType(), False),\n",
    "        StructField(\"hack_license\", StringType(), False),\n",
    "        StructField(\"vendor_id\", StringType(), False),\n",
    "        StructField(\"rate_code\", StringType(), False),\n",
    "        StructField(\"store_and_fwd_flag\", StringType(), False),\n",
    "        StructField(\"pickup_datetime\", TimestampType(), False),\n",
    "        StructField(\"dropoff_datetime\", TimestampType(), False),\n",
    "        StructField(\"passenger_count\", StringType(), False),\n",
    "        StructField(\"trip_time_in_secs\", StringType(), False),\n",
    "        StructField(\"trip_distance\", StringType(), False),\n",
    "        StructField(\"pickup_longitude\", StringType(), False),\n",
    "        StructField(\"pickup_latitude\", StringType(), False),\n",
    "        StructField(\"dropoff_longitude\", StringType(), False),\n",
    "        StructField(\"dropoff_latitude\", StringType(), False),\n",
    "        StructField(\"timestamp\", TimestampType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "casted_trip_schema = StructType(\n",
    "    [\n",
    "        StructField(\"medallion\", StringType(), False),\n",
    "        StructField(\"hack_license\", StringType(), False),\n",
    "        StructField(\"vendor_id\", StringType(), False),\n",
    "        StructField(\"rate_code\", IntegerType(), False),\n",
    "        StructField(\"store_and_fwd_flag\", StringType(), False),\n",
    "        StructField(\"pickup_datetime\", TimestampType(), False),\n",
    "        StructField(\"dropoff_datetime\", TimestampType(), False),\n",
    "        StructField(\"passenger_count\", IntegerType(), False),\n",
    "        StructField(\"trip_time_in_secs\", DoubleType(), False),\n",
    "        StructField(\"trip_distance\", DoubleType(), False),\n",
    "        StructField(\"pickup_longitude\", DoubleType(), False),\n",
    "        StructField(\"pickup_latitude\", DoubleType(), False),\n",
    "        StructField(\"dropoff_longitude\", DoubleType(), False),\n",
    "        StructField(\"dropoff_latitude\", DoubleType(), False),\n",
    "        StructField(\"timestamp\", TimestampType(), False),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "fare_schema = StructType(\n",
    "    [\n",
    "        StructField(\"medallion\", StringType(), False),\n",
    "        StructField(\"hack_license\", StringType(), False),\n",
    "        StructField(\"vendor_id\", StringType(), False),\n",
    "        StructField(\"pickup_datetime\", TimestampType(), False),\n",
    "        StructField(\"payment_type\", StringType(), False),\n",
    "        StructField(\"fare_amount\", DoubleType(), False),\n",
    "        StructField(\"surcharge\", DoubleType(), False),\n",
    "        StructField(\"mta_tax\", DoubleType(), False),\n",
    "        StructField(\"tip_amount\", DoubleType(), False),\n",
    "        StructField(\"tolls_amount\", DoubleType(), False),\n",
    "        StructField(\"total_amount\", DoubleType(), False),\n",
    "        StructField(\"timestamp\", TimestampType(), False),\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69712d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "lines = (spark.readStream                        # Get the DataStreamReader\n",
    "  .format(\"kafka\")                                 # Specify the source format as \"kafka\"\n",
    "  .option(\"kafka.bootstrap.servers\", BOOTSTRAP_SERVERS) # Configure the Kafka server name and port\n",
    "  .option(\"subscribe\", TRIP_TOPIC)                       # Subscribe to the \"en\" Kafka topic \n",
    "  .option(\"startingOffsets\", \"earliest\")           # The start point when a query is started\n",
    "  .option(\"maxOffsetsPerTrigger\", 100)             # Rate limit on max offsets per trigger interval\n",
    "  .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832dd5ee",
   "metadata": {},
   "source": [
    "## Utils\n",
    "\n",
    "This section contains  utlitity functions that will be used throughout the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "aac24999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_streams():\n",
    "    return [a.name for a in spark.streams.active]\n",
    "\n",
    "def stop_stream(name):\n",
    "    for stream in spark.streams.active:\n",
    "        if stream.name == name:\n",
    "            stream.stop()\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def inmemory_stream(df, wait_seconds=5, output_mode=\"append\"):\n",
    "    temp_table_name = f\"inmemory_{uuid.uuid4().hex}\"\n",
    "    query = (\n",
    "        df.writeStream.outputMode(output_mode)\n",
    "        .format(\"memory\")\n",
    "        .queryName(temp_table_name)\n",
    "        .start()\n",
    "    )\n",
    "\n",
    "    time.sleep(wait_seconds)\n",
    "    result = spark.sql(f\"SELECT * FROM {temp_table_name}\")\n",
    "    stop_stream(query.name)\n",
    "    return result\n",
    "\n",
    "def is_coordinate_in_polygon(longitude, latitude, polygon):\n",
    "    num = len(polygon)\n",
    "    i = 0\n",
    "    j = num - 1\n",
    "    is_inside = False\n",
    "    for i in range(num):\n",
    "        if ((polygon[i][1] > latitude) != (polygon[j][1] > latitude)) and (\n",
    "            longitude\n",
    "            < polygon[i][0]\n",
    "            + (polygon[j][0] - polygon[i][0])\n",
    "            * (latitude - polygon[i][1])\n",
    "            / (polygon[j][1] - polygon[i][1])\n",
    "        ):\n",
    "            is_inside = not is_inside\n",
    "        j = i\n",
    "    return is_inside\n",
    "\n",
    "def find_borough(longitude, latitude, nyc_boroughs):\n",
    "    for _, item in nyc_boroughs.value.items():\n",
    "        if item is None or item[0] is None:\n",
    "            continue\n",
    "        geometry = item[0]\n",
    "        polygons = geometry[\"coordinates\"]\n",
    "\n",
    "        properties = item[1]\n",
    "        borough = properties[\"borough\"]\n",
    "        borough_code = properties[\"boroughCode\"]\n",
    "\n",
    "        if any([is_coordinate_in_polygon(longitude, latitude, polygon) for polygon in polygons]):\n",
    "            return borough\n",
    "    return \"Other\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a46c68-44ab-4e3a-90fb-d334423e4acc",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24187ef-e5b4-4fa7-bab5-60aa94412a05",
   "metadata": {},
   "source": [
    "### QUERY-1\n",
    "\n",
    "Utilization over a window of 5, 10, and 15 minutes per taxi/driver. This can be computed by computing the idle time per taxi. How does it change? Is there an optimal window?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b2d7ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- hack_license: string (nullable = true)\n",
      " |-- vendor_id: string (nullable = true)\n",
      " |-- rate_code: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_time_in_secs: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trips_df = lines.select(from_json(col(\"value\").cast(\"string\"), plain_trip_schema).alias(\"parsed_value\"))\n",
    "trips_df = trips_df.select(\"parsed_value.*\")\n",
    "\n",
    "for field in casted_trip_schema.fields:\n",
    "    trips_df = trips_df.withColumn(field.name, col(field.name).cast(field.dataType))\n",
    "\n",
    "trips_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aeae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window, col, max, min\n",
    "\n",
    "window_durations = [5 * 60, 10 * 60, 15 * 60]\n",
    "\n",
    "for window_duration in window_durations:\n",
    "    window_col = window(\"pickup_datetime\", \"{} seconds\".format(window_duration))\n",
    "    df_windowed = trips_df.groupBy(\"medallion\", window_col).agg((max(\"dropoff_datetime\").cast(\"long\") - min(\"pickup_datetime\").cast(\"long\")).alias(\"busy_time\"))\n",
    "    \n",
    "    df_windowed = df_windowed.withColumn(\"idle_time\", window_duration - col(\"busy_time\"))\n",
    "    \n",
    "    df_windowed = df_windowed.withColumn(\"utilization\", col(\"busy_time\") / window_duration)\n",
    "    \n",
    "    query = (df_windowed.writeStream\n",
    "      .outputMode(\"complete\")\n",
    "      .format(\"memory\")\n",
    "      .queryName(\"utilization_{}_minutes\".format(window_duration // 60))\n",
    "      .trigger(processingTime=\"5 second\")\n",
    "      .start())\n",
    "\n",
    "spark.sql(\"SELECT * FROM utilization_5_minutes\").show()\n",
    "spark.sql(\"SELECT * FROM utilization_10_minutes\").show()\n",
    "spark.sql(\"SELECT * FROM utilization_15_minutes\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746caef-fc7c-4d0e-98df-cdd6046393eb",
   "metadata": {},
   "source": [
    "### QUERY-2 \n",
    "\n",
    "The average time it takes for a taxi to find its next fare(trip) per destination borough. This can be computed by finding the time difference, e.g. in seconds, between the trip's drop off and the next trip's pick up within a given unit of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d729c378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      " |-- geometry: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- properties: struct (nullable = true)\n",
      " |    |-- @id: string (nullable = true)\n",
      " |    |-- borough: string (nullable = true)\n",
      " |    |-- boroughCode: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyc_boroghs_df = spark.read.json(NYC_BOROUGHS_GEOJSON)\n",
    "nyc_boroghs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "752985dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "\n",
    "nyc_borogh_clean_df = nyc_boroghs_df.select(\"id\", struct(\"geometry\", \"properties\", \"type\").alias(\"value\"))\n",
    "nyc_borough_dict = nyc_borogh_clean_df.rdd.collectAsMap()\n",
    "nyc_borough_broadcast = spark.sparkContext.broadcast(nyc_borough_dict)\n",
    "\n",
    "def find_nyc_borough(longitude, latitude):\n",
    "    global nyc_borough_broadcast\n",
    "    return find_borough(longitude, latitude, nyc_borough_broadcast)\n",
    "\n",
    "assert find_nyc_borough(-73.978165,40.757977) == \"Manhattan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1ca665c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- stop_borough: string (nullable = true)\n",
      " |-- start_borough: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "find_borough_udf = udf(find_nyc_borough, StringType())\n",
    "\n",
    "borough_df = (\n",
    "    trips_df.select(\"dropoff_longitude\", \"dropoff_latitude\", \"pickup_longitude\", \"pickup_latitude\", \"pickup_datetime\", \"dropoff_datetime\", \"passenger_count\", \"timestamp\")\n",
    "    .withColumn(\"stop_borough\", find_borough_udf(\"dropoff_longitude\", \"dropoff_latitude\"))\n",
    "    .withColumn(\"start_borough\", find_borough_udf(\"pickup_longitude\", \"pickup_latitude\"))\n",
    ")\n",
    "\n",
    "borough_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dd85c676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+---------------+-------------------+-------------------+---------------+------------+-------------+\n",
      "|dropoff_longitude|dropoff_latitude|pickup_longitude|pickup_latitude|    pickup_datetime|   dropoff_datetime|passenger_count|stop_borough|start_borough|\n",
      "+-----------------+----------------+----------------+---------------+-------------------+-------------------+---------------+------------+-------------+\n",
      "|       -73.989838|       40.751171|      -73.978165|      40.757977|2013-01-01 15:11:48|2013-01-01 15:18:10|              4|   Manhattan|    Manhattan|\n",
      "|       -73.994499|        40.75066|      -74.006683|      40.731781|2013-01-06 00:18:35|2013-01-06 00:22:54|              1|   Manhattan|    Manhattan|\n",
      "|       -74.009834|       40.726002|      -74.004707|       40.73777|2013-01-05 18:49:41|2013-01-05 18:54:23|              1|   Manhattan|    Manhattan|\n",
      "|       -73.984734|       40.759388|      -73.974602|      40.759945|2013-01-07 23:54:15|2013-01-07 23:58:20|              2|   Manhattan|    Manhattan|\n",
      "|       -74.002586|       40.747868|       -73.97625|      40.748528|2013-01-07 23:25:03|2013-01-07 23:34:24|              1|   Manhattan|    Manhattan|\n",
      "|       -73.983322|       40.743763|      -73.966743|      40.764252|2013-01-07 15:27:48|2013-01-07 15:38:37|              1|   Manhattan|    Manhattan|\n",
      "|       -74.007416|       40.744343|      -73.995804|      40.743977|2013-01-08 11:01:15|2013-01-08 11:08:14|              1|   Manhattan|    Manhattan|\n",
      "|        -73.86525|        40.77063|      -73.989937|      40.756775|2013-01-07 12:39:18|2013-01-07 13:10:56|              3|      Queens|    Manhattan|\n",
      "|       -73.982712|       40.735336|      -73.980072|      40.743137|2013-01-07 18:15:47|2013-01-07 18:20:47|              1|   Manhattan|    Manhattan|\n",
      "|       -73.952919|        40.80637|      -73.977936|      40.786983|2013-01-07 15:33:28|2013-01-07 15:49:26|              2|   Manhattan|    Manhattan|\n",
      "|       -73.964134|       40.773815|      -73.982452|      40.773167|2013-01-08 13:11:52|2013-01-08 13:19:50|              1|   Manhattan|    Manhattan|\n",
      "|       -73.988686|       40.759052|       -73.99556|      40.749294|2013-01-08 09:50:05|2013-01-08 10:02:54|              1|   Manhattan|    Manhattan|\n",
      "|       -73.964478|       40.775921|      -73.971497|      40.791321|2013-01-10 12:07:08|2013-01-10 12:17:29|              1|   Manhattan|    Manhattan|\n",
      "|       -73.981094|       40.755325|       -73.98851|      40.774307|2013-01-07 07:35:47|2013-01-07 07:46:00|              1|   Manhattan|    Manhattan|\n",
      "|       -73.971558|       40.761612|      -73.994911|      40.723221|2013-01-10 15:42:29|2013-01-10 16:04:02|              1|   Manhattan|    Manhattan|\n",
      "|       -73.987846|       40.756104|      -74.010391|      40.708702|2013-01-10 14:27:28|2013-01-10 14:45:21|              1|   Manhattan|    Manhattan|\n",
      "|       -73.998413|       40.756832|      -73.973732|      40.756287|2013-01-07 22:09:59|2013-01-07 22:19:50|              1|   Manhattan|    Manhattan|\n",
      "|        -73.96199|       40.776566|      -73.968925|      40.767704|2013-01-07 17:18:16|2013-01-07 17:20:55|              1|   Manhattan|    Manhattan|\n",
      "|       -73.979561|        40.75539|       -73.96212|      40.769737|2013-01-07 06:08:51|2013-01-07 06:13:14|              1|   Manhattan|    Manhattan|\n",
      "|       -73.977615|       40.787575|      -73.989708|      40.756714|2013-01-07 22:25:46|2013-01-07 22:36:56|              1|   Manhattan|    Manhattan|\n",
      "+-----------------+----------------+----------------+---------------+-------------------+-------------------+---------------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inmemory_stream(borough_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f1721766",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_count_avg = borough_df.groupBy(\"stop_borough\").agg(avg(\"passenger_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3a7b4a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|stop_borough|avg(passenger_count)|\n",
      "+------------+--------------------+\n",
      "|   Manhattan|  1.3636363636363635|\n",
      "|      Queens|                 3.0|\n",
      "+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inmemory_stream(passenger_count_avg, output_mode=\"update\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.orderBy(\"pickup_datetime\")\n",
    "\n",
    "average_time_to_next_trip = borough_df.withColumn(\"next_pickup_datetime\", lag(borough_df[\"pickup_datetime\"]).over(window))\n",
    "average_time_to_next_trip = borough_df.withColumn(\"time_to_next_fare\", unix_timestamp(\"next_pickup_datetime\") - unix_timestamp(\"dropoff_datetime\"))\n",
    "average_time_to_next_trip = borough_df.groupBy(\"stop_borough\").agg(avg(\"time_to_next_fare\"))\n",
    "\n",
    "inmemory_stream(average_time_to_next_trip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8268c285-d55c-4be3-8e5a-e7ddebb14153",
   "metadata": {},
   "source": [
    "### QUERY-3\n",
    "\n",
    "The number of trips that started and ended within the same borough in the last hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "77c7f81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Column<'(current_timestamp() - INTERVAL '11' YEAR)'>,\n",
       " Column<'((current_timestamp() - INTERVAL '11' YEAR) - INTERVAL '5' MONTH)[100]'>)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from current timestamp reduce 11 years and 5 months\n",
    "from pyspark.sql.functions import current_timestamp, expr\n",
    "\n",
    "current_time = current_timestamp()\n",
    "eleven_years_ago = current_time - expr(\"INTERVAL 11 YEARS\")\n",
    "five_months_ago = eleven_years_ago - expr(\"INTERVAL 5 MONTHS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3369625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|current_time              |\n",
      "+--------------------------+\n",
      "|2024-06-06 09:50:51.405526|\n",
      "+--------------------------+\n",
      "\n",
      "+-------------------------+\n",
      "|eleven_years_ago         |\n",
      "+-------------------------+\n",
      "|2013-06-06 09:50:51.93668|\n",
      "+-------------------------+\n",
      "\n",
      "+--------------------------+\n",
      "|five_months_ago           |\n",
      "+--------------------------+\n",
      "|2013-01-06 09:50:52.093186|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_time = spark.range(1).select(current_timestamp().alias(\"current_time\"))\n",
    "eleven_years_ago = current_time.select((current_time[\"current_time\"] - expr(\"INTERVAL 11 YEARS\")).alias(\"eleven_years_ago\"))\n",
    "five_months_ago = eleven_years_ago.select((eleven_years_ago[\"eleven_years_ago\"] - expr(\"INTERVAL 5 MONTHS\")).alias(\"five_months_ago\"))\n",
    "\n",
    "current_time.show(truncate=False)\n",
    "eleven_years_ago.show(truncate=False)\n",
    "five_months_ago.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "403d7fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+----------+\n",
      "|              window|start_borough|stop_borough|trip_count|\n",
      "+--------------------+-------------+------------+----------+\n",
      "|{2024-06-04 00:00...|    Manhattan|   Manhattan|        21|\n",
      "+--------------------+-------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp, unix_timestamp, lit, hour, expr, window, count\n",
    "\n",
    "current_time = current_timestamp()\n",
    "eleven_years_ago = current_time - expr(\"INTERVAL 11 YEARS\")\n",
    "# current_time = eleven_years_ago - expr(\"INTERVAL 5 MONTHS\")\n",
    "\n",
    "# one_hour_ago = (unix_timestamp(current_time) - lit(60*360_000)).cast(\"timestamp\")\n",
    "one_hour_ago = (unix_timestamp(eleven_years_ago) - lit(60*216000)).cast(\"timestamp\")\n",
    "\n",
    "same_borough_trips =(\n",
    "    borough_df\n",
    "    .filter(col(\"start_borough\") == col(\"stop_borough\"))\n",
    "    .groupBy(\n",
    "        window(\"timestamp\", \"1440 minutes\", \"1440 minutes\"), \"start_borough\" , \"stop_borough\"\n",
    "    )\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"trip_count\")\n",
    "    )\n",
    ")\n",
    "\n",
    "inmemory_stream(same_borough_trips, output_mode=\"update\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b7e7ad21-59c2-4d4c-befe-9d1ceedbb74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+----------------+---------------+-------------------+-------------------+---------------+------------+-------------+\n",
      "|dropoff_longitude|dropoff_latitude|pickup_longitude|pickup_latitude|    pickup_datetime|   dropoff_datetime|passenger_count|stop_borough|start_borough|\n",
      "+-----------------+----------------+----------------+---------------+-------------------+-------------------+---------------+------------+-------------+\n",
      "|       -73.984734|       40.759388|      -73.974602|      40.759945|2013-01-07 23:54:15|2013-01-07 23:58:20|              2|   Manhattan|    Manhattan|\n",
      "|       -74.002586|       40.747868|       -73.97625|      40.748528|2013-01-07 23:25:03|2013-01-07 23:34:24|              1|   Manhattan|    Manhattan|\n",
      "|       -73.983322|       40.743763|      -73.966743|      40.764252|2013-01-07 15:27:48|2013-01-07 15:38:37|              1|   Manhattan|    Manhattan|\n",
      "|       -74.007416|       40.744343|      -73.995804|      40.743977|2013-01-08 11:01:15|2013-01-08 11:08:14|              1|   Manhattan|    Manhattan|\n",
      "|       -73.982712|       40.735336|      -73.980072|      40.743137|2013-01-07 18:15:47|2013-01-07 18:20:47|              1|   Manhattan|    Manhattan|\n",
      "|       -73.952919|        40.80637|      -73.977936|      40.786983|2013-01-07 15:33:28|2013-01-07 15:49:26|              2|   Manhattan|    Manhattan|\n",
      "|       -73.964134|       40.773815|      -73.982452|      40.773167|2013-01-08 13:11:52|2013-01-08 13:19:50|              1|   Manhattan|    Manhattan|\n",
      "|       -73.988686|       40.759052|       -73.99556|      40.749294|2013-01-08 09:50:05|2013-01-08 10:02:54|              1|   Manhattan|    Manhattan|\n",
      "|       -73.964478|       40.775921|      -73.971497|      40.791321|2013-01-10 12:07:08|2013-01-10 12:17:29|              1|   Manhattan|    Manhattan|\n",
      "|       -73.971558|       40.761612|      -73.994911|      40.723221|2013-01-10 15:42:29|2013-01-10 16:04:02|              1|   Manhattan|    Manhattan|\n",
      "|       -73.987846|       40.756104|      -74.010391|      40.708702|2013-01-10 14:27:28|2013-01-10 14:45:21|              1|   Manhattan|    Manhattan|\n",
      "|       -73.998413|       40.756832|      -73.973732|      40.756287|2013-01-07 22:09:59|2013-01-07 22:19:50|              1|   Manhattan|    Manhattan|\n",
      "|        -73.96199|       40.776566|      -73.968925|      40.767704|2013-01-07 17:18:16|2013-01-07 17:20:55|              1|   Manhattan|    Manhattan|\n",
      "|       -73.977615|       40.787575|      -73.989708|      40.756714|2013-01-07 22:25:46|2013-01-07 22:36:56|              1|   Manhattan|    Manhattan|\n",
      "|       -73.996368|        40.73246|      -73.956505|      40.771278|2013-01-07 18:05:36|2013-01-07 18:23:50|              4|   Manhattan|    Manhattan|\n",
      "|       -73.967285|       40.763344|       -73.95578|       40.77932|2013-01-08 13:29:25|2013-01-08 13:37:52|              1|   Manhattan|    Manhattan|\n",
      "+-----------------+----------------+----------------+---------------+-------------------+-------------------+---------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp, unix_timestamp, lit, hour\n",
    "\n",
    "current_time = current_timestamp()\n",
    "eleven_years_ago = current_time - expr(\"INTERVAL 11 YEARS\")\n",
    "# current_time = eleven_years_ago - expr(\"INTERVAL 5 MONTHS\")\n",
    "\n",
    "# one_hour_ago = (unix_timestamp(current_time) - lit(60*360_000)).cast(\"timestamp\")\n",
    "one_hour_ago = (unix_timestamp(eleven_years_ago) - lit(60*216000)).cast(\"timestamp\")\n",
    "\n",
    "same_borough_trips = borough_df.filter(\n",
    "    (col(\"start_borough\") == col(\"stop_borough\")) & \n",
    "    (col(\"pickup_datetime\") >= one_hour_ago) & \n",
    "    (col(\"pickup_datetime\") <= current_time)\n",
    ")\n",
    "\n",
    "inmemory_stream(same_borough_trips).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0d685-c3ed-4b7d-8ebc-c3174ba55645",
   "metadata": {},
   "source": [
    "### QUERY-4 \n",
    "\n",
    "The number of trips that started in one borough and ended in another one in the last hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f1f3578b-1960-4969-801b-adc2f45493a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+------------+----------+\n",
      "|              window|start_borough|stop_borough|trip_count|\n",
      "+--------------------+-------------+------------+----------+\n",
      "|{2024-06-04 00:00...|       Queens|   Manhattan|         1|\n",
      "|{2024-06-04 00:00...|    Manhattan|      Queens|         1|\n",
      "+--------------------+-------------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp, unix_timestamp, lit, hour, expr, window, count\n",
    "\n",
    "current_time = current_timestamp()\n",
    "eleven_years_ago = current_time - expr(\"INTERVAL 11 YEARS\")\n",
    "\n",
    "one_hour_ago = (unix_timestamp(eleven_years_ago) - lit(60*216000)).cast(\"timestamp\")\n",
    "\n",
    "same_borough_trips =(\n",
    "    borough_df\n",
    "    .filter(col(\"start_borough\") != col(\"stop_borough\"))\n",
    "    .groupBy(\n",
    "        window(\"timestamp\", \"1440 minutes\", \"1440 minutes\"), \"start_borough\" , \"stop_borough\"\n",
    "    )\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"trip_count\")\n",
    "    )\n",
    ")\n",
    "\n",
    "inmemory_stream(same_borough_trips, output_mode=\"update\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77f066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
